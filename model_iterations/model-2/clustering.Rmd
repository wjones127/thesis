---
title: "Rider Clustering"
author: "Will Jones"
date: "April 1, 2016"
output: html_document
---

```{r load-packages, echo=F, results='hide', message=F}
packages <- c("dplyr", "ggplot2", "ggthemes", "caret", "lubridate", "gamm4",
              "gridExtra", "binom", "tidyr", "knitr", "stargazer", "extrafont", "AUC")
sapply(packages, library, character.only = TRUE)
source("prob-var-plot.R")
source("separation-plot.R")
```


```{r load-data, echo=F}
# Load data
#load('./rides.RData')
#rides_final <- rides %>%
#  mutate(length_meters = length)

rides <- read.csv('sample.csv',
                  col.names = c("trip_id", "rider", "length_meters", 
                                "datetime", "rating", "rating_text"),
                  colClasses = c("character", "factor", "numeric", 
                                 "character", "factor", "factor"))
rides_final <- rides %>%
  mutate(datetime = ymd_hms(datetime, tz="America/Los_Angeles"),
         stressful = ifelse(rating_text == "none", NA,
                            ifelse(rating_text == "good", FALSE, TRUE)),
         rider = as.factor(as.numeric(rider)))

###################################
## Comment this out later!!!
# Shift the dates for the test data
#day(rides_final$datetime) <- day(rides_final$datetime) - 200
#rides_final$rider <- as.factor(rep(1:3, length.out = nrow(rides_final)))

load('./weather_daily.RData')
load('./rain_hourly.RData')
```

```{r transform-data, echo=F}
# Join in various data sources
rides_final <- rides_final %>%
  mutate(date = floor_date(datetime, "day")) %>%
  left_join(weather, by = "date") %>%
  mutate(datetime_hour = floor_date(datetime, "hour")) %>%
  left_join(rain, by=c("datetime_hour" = "datetime"))

rides_final <- mutate(rides_final, time = datetime)
day(rides_final$time) <- 1
month(rides_final$time) <- 1
year(rides_final$time) <- 2015
rides_final <- rides_final %>%
  mutate(time = as.numeric(time),
         time = time - min(time),
         time = time / 3600) # convert time from seconds to hours

rides_final$weekend <- as.factor(wday(rides_final$datetime) %in% c(1, 7))

# Filter out the rides with zero length
rides_scaled <- rides_final %>% filter(length_meters != 0)

# Scale the variables
scaled_log_length <- scale(log(rides_scaled$length_meters))
scaled_length <- scale(rides_scaled$length_meters)
scaled_temp <- scale(rides_scaled$mean.temp)
rides_scaled$length <- scaled_length[,1]
rides_scaled$log_length <- scaled_log_length[,1]
rides_scaled$mean.temp <- scaled_temp[,1]
rides_scaled <- rides_scaled %>%
  filter(!is.na(mean.temp) &
         !is.na(rainfall))

# Find riders with at least 20 rated rides
rider_counts <- rides_scaled %>% group_by(rider) %>% summarise(count = n()) %>%
  filter(count > 20)
rides_scaled <- rides_scaled %>% filter(rider %in% rider_counts$rider)


rides_scaled <- rides_scaled %>%
  mutate(gust.speed = ifelse(is.na(gust.speed), 0, gust.speed))

# Filter out riders that don't rate any rides
riders <- rides_scaled$rider %>% unique()
riders_with_ratings <- filter(rides_scaled, !is.na(stressful))$rider %>% unique()
riders_without_ratings <- riders[!riders %in% riders_with_ratings]
rides_scaled <- filter(rides_scaled, !rider %in% riders_without_ratings)

# Reset the rider indexes
rides_scaled$rider <- rides_scaled$rider %>%
  as.numeric() %>%
  as.factor() %>%
  plyr::mapvalues(from = levels(.),
                  to = 1:length(levels(.)))

```

```{r sample-riders}
some_riders <- rides_scaled$rider %>% unique() %>% sample(9)
#rides_scaled <- rides_scaled %>% filter(rider %in% some_riders)
```


```{r}
ggplot(filter(rides_scaled), aes(x = time, y = log_length)) + 
 # geom_point(alpha = 0.2) +
stat_density_2d(geom = "raster", aes(fill = ..density..), contour = FALSE) +
    scale_x_continuous(breaks = c(0, 6, 12, 18, 24),
                     labels = c("12am", "6am", "12pm", "6pm", "12am")) + 
  scale_fill_gradientn(colors = rainbow(7)) +
  #scale_fill_gradient(low = "white", high = "black") + 
  theme_bw(base_family="CMU Serif") + 
  facet_wrap(~weekend)

ggplot(filter(rides_scaled, rider %in% some_riders & weekend == TRUE), 
       aes(x = time, y = log_length)) + 
stat_density_2d(geom = "raster", aes(fill = ..density..), contour = FALSE) +
    scale_x_continuous(breaks = c(0, 6, 12, 18, 24),
                     labels = c("12am", "6am", "12pm", "6pm", "12am")) + 
  scale_fill_gradientn(colors = rainbow(7)) +
  theme_bw(base_family="CMU Serif") + 
  facet_wrap(~rider, nrow = 3)
```

Feature ideas:

- Concentration of peaks: pareto fit for weekend and weekdays
- balance of rides before / after noon
- balance of ride length sum for before / after noon
- median ride length weekday
- median ride length weekend - weekday
- variance of length

# Classifying Riders

We need to understand how riders differ. Our result from the previous chapter
underscore this need. Clearly there are different types of riders, and this
accounts for a huge amount of the patterns in how riders ride. We can get for
each rider

- Frequency of rides, in rides per week
- Proportion of rides on weekends
- Patterns in time of day on weekdays
- Patterns in ride length

The last two are a little vague. How can we get variables that describe patterns
of rides? Summary statistics like mean and variance can help, but really don't
give a great description of rider patterns. How would mean time of day help us?
Instead, we can transform time of day and length patterns into high dimensional
varianbles and then do principle component analysis (PCA) to create summaries
that best describe those distributions. We keep these as two separate PCA 
a distinct from other variables to keep some interprebility in this model. 

```{r rider-freq}
# Compute rider averages
riders <- rides_scaled %>%
  group_by(rider) %>%
  summarise(first_date = min(datetime),
            last_date = max(datetime),
            count = n(),
            prop_weekend = sum(weekend == TRUE) / count,
            count_balance = sum(weekend == TRUE & between(time, 0, 12)) / count,
            length_balance = sum(log_length * (weekend == FALSE & between(time, 0, 12))) /
              sum(log_length * (weekend == FALSE)),
            median_length = median(log_length * (weekend == FALSE)),
            median_length_diff = median_length - median(log_length * (weekend == TRUE)),
            var_length = var(log_length)) %>%
  mutate(freq = 7 * count / as.numeric(last_date - first_date))

qplot(x = freq, data = riders, bins = 40) + 
  labs(title = "Ride Frequency by Rider",
  x = "Rides per Week", 
  y = "Count") +
  theme_bw()
```

# Game plan

Okay, so here's the game plan:

1. Compute freq of rides
2. Do PCA for length and time patterns (would quantiles work better for length?)
3. Take freq. of rides, PC1 & PC2 from length and time patterns
4. Do clustering of riders
5. Plot avg pattern for each cluster, describe


## Length patterns



```{r length-pca}
hist(rides_scaled$log_length)
bins <- 12
rider_length_table <- table(as.character(rides_scaled$rider), 
      cut(rides_scaled$log_length, 
          breaks = seq(from = -5, to = 2, length = bins + 1)))
rider_length_dist <- rider_length_table %>% 
  data.frame() %>%
  rename(rider = Var1)

rider_lengths <- spread(rider_length_dist, Var2, Freq)

rider_lengths <- cbind(rider_lengths$rider, 
                           rider_lengths[, -1] / rowSums(rider_lengths[, -1])) %>%
  rename(rider = `rider_lengths$rider`)

pc_length <- prcomp(rider_lengths[,-1], scale = TRUE)

length_scree <- qplot(x = 1:length(pc_length$sdev), y = pc_length$sdev^2 / sum(pc_length$sdev^2)) + 
  geom_line() + 
  labs(title = "Ride Length PCA Scree Plot",
       x = "Principle Component",
       y = "Prop. of Var. Explained") + 
  theme_bw(base_family="CMU Serif")

length_scree

ggsave("plots/length_scree.pdf", width = 4, height = 3)

pc_length_rotation <- data.frame("length" = rownames(pc_length$rotation),
                                 pc_length$rotation) %>%
  tbl_df() %>%
  select(length, PC1, PC2, PC3, PC4) %>%
  gather(pc, value, -length)

length_loadings <- ggplot(pc_length_rotation, aes(x = length, y = value)) + 
  geom_bar(stat = "identity") + 
  facet_wrap(~pc, ncol = 1)+
  scale_x_discrete(breaks = NULL) +
    scale_y_continuous(breaks = c(-0.3, 0, 0.3)) +
  theme_bw(base_family="CMU Serif") + 
  labs(title = "Length PCA Loadings",
       x = "standardized log(length)")

length_loadings

ggsave("plots/length_loadings.pdf", width = 3, height = 4)

rider_lengths_w_pc <- cbind(rider_lengths, pc_length$x)

#qplot(x = PC1, y = PC2, data = rider_lengths_w_pc)
```

```{r length-pca2, eval = FALSE}
hist(rides_scaled$log_length)
bins <- 12
rider_length_table2 <- table(as.character(rides_scaled$rider), 
      cut(rides_scaled$log_length, 
          breaks = seq(from = -5, to = 2, length = bins + 1)))
rider_length_dist2 <- rider_length_table2 %>% 
  data.frame() %>%
  rename(rider = Var1)

rider_lengths2 <- spread(rider_length_dist2, Var2, Freq)

rider_lengths2 <- cbind(rider_lengths2$rider, 
                           rider_lengths2[, -1] / rowSums(rider_lengths2[, -1])) %>%
  rename(rider = `rider_lengths2$rider`)

names(rider_lengths2) <- c("rider", as.character(1:12))

add_pow <- function(data, pow) {
  for (var in 1:12) {
    var_name <- paste(var, pow, sep="^")
    data[[var_name]] <- data[[as.character(var)]]^pow
  }
  data 
}

rider_lengths2 <- rider_lengths2 %>% add_pow(2) %>% add_pow(3) %>% add_pow(4)

pc_length2 <- prcomp(rider_lengths2[,-1], scale = TRUE)

length_scree2 <- qplot(x = 1:length(pc_length2$sdev), y = pc_length2$sdev^2 / sum(pc_length2$sdev^2)) + 
  geom_line() + 
  labs(title = "Ride Length PCA Scree Plot",
       x = "Principle Component",
       y = "Prop. of Var. Explained") + 
  theme_bw(base_family="CMU Serif")

length_scree2

ggsave("plots/length_scree2.pdf", width = 4, height = 3)

pc_length_rotation2 <- data.frame("length" = rownames(pc_length2$rotation),
                                 pc_length2$rotation) %>%
  tbl_df() %>%
  select(length, PC1, PC2, PC3, PC4) %>%
  gather(pc, value, -length)

length_loadings2 <- ggplot(pc_length_rotation2, aes(x = length, y = value)) + 
  geom_bar(stat = "identity") + 
  facet_wrap(~pc, ncol = 2)+
  scale_x_discrete(breaks = NULL) +
  theme_bw(base_family="CMU Serif") + 
  labs(title = "Time PCA Loadings",
       x = "standardized log(length)")

length_loadings2

ggsave("plots/length_loadings2.pdf", width = 3, height = 2)

rider_lengths_w_pc2 <- cbind(rider_lengths2, pc_length2$x)

#qplot(x = PC1, y = PC2, data = rider_lengths_w_pc)
```


## Time Patterns

Let's try to use PCA to create simple vectors to describe people's time of ride
patterns. 

```{r time-pca}
rider_weekday_times <- rides_scaled %>%
  filter(weekend == FALSE) %>%
  mutate(time = floor(time)) 

rider_times <- table(as.factor(as.numeric(rider_weekday_times$rider)),
                     rider_weekday_times$time) %>% 
  data.frame() %>%
  rename(rider = Var1, time = Var2, freq = Freq) %>%
  spread(time, freq)

# Let's normalize the rider times
rider_times <- cbind(rider_times$rider, 
                           rider_times[, -1] / rowSums(rider_times[, -1])) %>%
  rename(rider = `rider_times$rider`)

pc <- prcomp(rider_times[,-1], scale=TRUE, retx = TRUE)


qplot(x = 1:length(pc$sdev), y = pc$sdev^2 / sum(pc$sdev^2)) + 
  geom_line() + 
  labs(title = "Scree Plot for Rider Variables",
       x = "Principle Component",
       y = "Proportion of Variance Explained") + 
  theme_bw(base_family="CMU Serif") 

pc_rotation <- data.frame("hour" = 1:length(pc$rotation), pc$rotation) %>%
  tbl_df() %>%
  select(hour, PC1, PC2, PC3, PC4) %>%
  gather(pc, value, -hour)

ggplot(pc_rotation, aes(x = hour, y = value)) + 
  geom_bar(stat = "identity") + 
  facet_wrap(~pc, ncol = 1) +
    theme_bw(base_family="CMU Serif") +
  labs(title = "Loadings for First Four Principal Compenents",
       x = "hour of day") + 
  scale_x_continuous(breaks = c(0, 3, 6, 9, 12, 15, 18, 21, 24))

rider_times_w_pc <- cbind(rider_times, pc$x)

clustering <- kmeans(select(rider_times_w_pc, PC1, PC2, PC3, PC4, PC5, PC6), 4, nstart = 30)

rider_times_w_pc$cluster <- as.factor(clustering$cluster)

qplot(x = PC1, y = PC2, color = cluster, data = rider_times_w_pc)
```

```{r alt-time-pca}
rider_times2 <- data.frame(rider_times[,1],
apply(rider_times[,-1], 1, sort, decreasing = TRUE) %>% t()) %>% tbl_df()

#rider_times2 <- rider_times2 %>% select(-X21, -X22, -X23)

remove_zero_cols <- function(M) M[, colSums(abs(M)) != 0]

rider_times2 <- cbind(rider_times2[,1], remove_zero_cols(rider_times2[,-1]))

pc2 <- prcomp(rider_times2[,-1], scale=TRUE, retx = TRUE)


time_scree <- qplot(x = 1:length(pc2$sdev), y = pc2$sdev^2 / sum(pc2$sdev^2)) + 
  geom_line() + 
  labs(title = "Ride Time PCA Scree Plot",
       x = "Principle Component",
       y = "Prop. of Var. Explained") + 
  theme_bw(base_family="CMU Serif") 

time_scree

ggsave("plots/time_scree.pdf", width = 4, height = 3)

pc_rotation2 <- data.frame("hour" = 1:(ncol(rider_times2)-1), pc2$rotation) %>%
  tbl_df() %>%
  select(hour, PC1, PC2, PC3, PC4) %>%
  gather(pc, value, -hour)

time_loadings <- ggplot(pc_rotation2, aes(x = hour, y = value)) + 
  geom_bar(stat = "identity") + 
  facet_wrap(~pc, ncol = 1) +
    theme_bw(base_family="CMU Serif") +
  labs(title = "Time PCA Loadings",
       x = "ranked hour") + 
  scale_y_continuous(breaks = c(-0.5, 0, 0.5)) +
  scale_x_continuous(breaks = seq(1, 20, by = 2))

time_loadings

ggsave("plots/time_loadings.pdf", width = 3, height = 4)

rider_times_w_pc2 <- cbind(rider_times2, pc2$x) %>% tbl_df() %>%
  rename(rider = rider_times...1.)
```
# Clustering

```{r clustering}
riders_final <- riders %>%
  left_join(select(rider_times_w_pc2, rider, PC1, PC2), by = "rider") %>%
  rename(time_pc1 = PC1, time_pc2 = PC2) %>%
  left_join(select(rider_lengths_w_pc, rider, PC1, PC2), by = "rider") %>%
  rename(length_pc1 = PC1, length_pc2 = PC2)

# Need to standardize these variables
scaled_freq <- scale(riders_final$freq)
scaled_weekend <- scale(riders_final$prop_weekend)
riders_final$freq <- scaled_freq[,1]
riders_final$prop_weekend <- scaled_weekend[,1]
riders_final$time_pc1 <- scale(riders_final$time_pc1)[,1]
riders_final$time_pc2 <- scale(riders_final$time_pc2)[,1]
riders_final$length_pc1 <- scale(riders_final$length_pc1)[,1]
riders_final$length_pc2 <- scale(riders_final$length_pc2)[,1]
riders_final$length_balance <- scale(riders_final$length_balance)[,1]
riders_final$count_balance <- scale(riders_final$count_balance)[,1]
riders_final$median_length <- scale(riders_final$median_length)[,1]
riders_final$median_length_diff <- scale(riders_final$median_length_diff)[,1]
riders_final$var_length <- scale(riders_final$var_length)[,1]

#clustering <- kmeans(select(riders_final, -first_date, -last_date, -rider, -count),4, nstart = 30)

clustering2 <- hclust(dist(select(riders_final, -first_date, -last_date, -rider, -count)),
                      method = "ward.D2")
riders_final$cluster <- as.factor(cutree(clustering2, k = 6))

#riders_final$cluster <- as.factor(clustering$cluster)

pc <- prcomp(select(riders_final, -first_date, -last_date, -rider, -count, -cluster))

riders_final <- riders_final %>% mutate(PC1 = pc$x[,1], PC2 = pc$x[,2])

scatter1 <- ggplot(riders_final, aes(x = time_pc1, y = time_pc2, color = cluster)) + 
  geom_point(size = .6) +
  theme_bw(base_family="CMU Serif") +
  labs(x = "Time PC1", y = "Time PC2") +
  theme(legend.position="top")
scatter2 <- ggplot(riders_final, aes(x = length_pc1, y = length_pc2, color = cluster)) +
    geom_point(size = .6) +
  theme_bw(base_family="CMU Serif") +
  labs(x = "Length PC1", y = "Length PC2") +
  theme(legend.position="top")
scatter3 <- ggplot(riders_final, aes(x = freq, y = prop_weekend, color = cluster)) +
    geom_point(size = .6) +
  theme_bw(base_family="CMU Serif") +
  labs(x = "rides per week", y = "prop. during weekend") +
  theme(legend.position="top")

scatter1
scatter2
scatter3

qplot(x = PC1, y = PC2, color = cluster, data = riders_final)

ggsave("plots/cluster_scatter1.pdf", scatter1, width = 3, height = 3.5)
ggsave("plots/cluster_scatter2.pdf", scatter2, width = 3, height = 3.5)
ggsave("plots/cluster_scatter3.pdf", scatter3, width = 3, height = 3.5)


#test_k <- function(k) kmeans(select(riders_final, -first_date, -last_date, -rider, -count), k, nstart = 40)$tot.withinss
#ss <- sapply(1:8, test_k)
# 
# choice_k <- qplot(x = 1:8, y = ss) + geom_line() +
#   labs(title = "Total Within SS by Choice of k",
#        x = "k",
#        y = "Total Within SS") + 
#   theme_bw(base_family="CMU Serif")
# 
# choice_k
# 
# ggsave("plots/choice_k.pdf", width = 4, height = 3)
```


```{r}
rides_scaled_w_cluster <- select(riders_final, rider, cluster) %>%
  right_join(rides_scaled, by = "rider") %>%
  mutate(weekend_named = as.factor(ifelse(weekend == TRUE, "weekend", "weekday")))

cluster_patterns <- rides_scaled_w_cluster %>%
 filter(rider != "242") %>%
ggplot(aes(x = time, y = log_length)) + 
  stat_density_2d(geom = "raster", aes(fill = ..density..), contour = FALSE) +
    scale_x_continuous(breaks = c(0, 6, 12, 18, 24),
                     labels = c("12am", "6am", "12pm", "6pm", "12am")) + 
  facet_grid(weekend_named ~ cluster) + 
  scale_fill_gradientn(colors = rainbow(7)) +
  #scale_fill_gradient(low = "white", high = "black") + 
  theme_bw(base_family="CMU Serif") + 
  labs(x = "time of day", y = "log(length)", 
       title = "Cluster Time and Length Patterns") +
  theme(axis.text.x=element_text(size=10, angle=50, vjust = 1.05, hjust = 1))

cluster_patterns

ggsave("plots/cluster_patterns.pdf", cluster_patterns, width = 6, height = 4)

```



## What if we fit models with these clusters?

```{r fit-models}
model0 <- gam(stressful ~ 1 + log_length + mean.temp + gust.speed +
                  rainfall + rainfall.4h  + s(time, bs="cc", k=9, by = weekend),
                knots=list(time=seq(0, 24, 3)),
                data = rides_scaled_w_cluster, family = binomial)

# Model 4 from last chapter
model1 <- gamm4(stressful ~ 1 + log_length + mean.temp + gust.speed +
                  rainfall + rainfall.4h  + s(time, bs="cc", k=9, by = weekend),
                random =~(1|rider),
                knots=list(time=seq(0, 24, 3)),
                data = rides_scaled_w_cluster, family = binomial)

# Model 4 but with cluster intercepts
model2 <- gamm4(stressful ~ 1 + log_length + mean.temp + gust.speed +
                  rainfall + rainfall.4h  + s(time, bs="cc", k=9, by = weekend),
                random =~(1|cluster),
                knots=list(time=seq(0, 24, 3)),
                data = rides_scaled_w_cluster, family = binomial)
```

```{r}
invlogit <- function (x) { 1 / (1 + exp(-x))}

# Trying to get predictions that combine smoothers and random intercept. It's hard.
predict_gamm <- function(model, newdata, group_name) {
  intercepts <- coef(model$mer)[[group_name]][["(Intercept)"]]
  intercept_vector <- intercepts[match(newdata[[group_name]], rownames(coef(model$mer)[[group_name]]))]
  invlogit(predict(model$gam, newdata = newdata) + intercept_vector)
}
```



```{r eval-models}
fitted_values <- data.frame("actual" = rides_scaled$stressful,
                            "predict0" = predict(model0, rides_scaled_w_cluster, type = "response"),
                            "predict1" = predict_gamm(model1, rides_scaled_w_cluster, "rider"),
                            "predict2" = predict_gamm(model2, rides_scaled_w_cluster, "cluster"))
fitted_values <- fitted_values[complete.cases(fitted_values),]



for (i in 0:2) {
  p <- separation_plot(fitted_values, "actual", paste("predict", as.character(i), sep = ""))
  ggsave(p, file=paste("plots/rider-model", as.character(i), "-sep.pdf", sep=""), 
         width = 4, height = 0.25)
}

# Loglikelihood
logLik(model0)
logLik(model1$mer)
logLik(model2$mer)

# AIC
AIC(model0)
AIC(model1$mer)
AIC(model2$mer)

# AUC
calc_auc <- function(model) auc(sensitivity(fitted_values[[model]], as.factor(as.numeric(fitted_values$actual))))
calc_auc("predict0")
calc_auc("predict1")
calc_auc("predict2")
```

Let's see how models in STAN do to compare
```{r stan-models}

rides_complete <- rides_scaled %>% filter(!is.na(stressful))

library(rstan)
rstan_options(auto_write = TRUE)
#package the data for stan
data = list(
  num_rides = length(rides_complete$stressful),
  num_cyclists = rides_complete$rider %>% unique() %>% length(),
  # Ride-level variables
  rating = as.numeric(rides_complete$stressful),
  length = as.numeric(rides_complete$log_length),
  mean_temp = as.numeric(rides_complete$mean.temp),
  gust_speed = rides_complete$gust.speed,
  rainfall = rides_complete$rainfall,
  rainfall_4h = rides_complete$rainfall.4h,
  cyclist = as.numeric(rides_complete$rider),
  # Cyclist-level variables
  cyclist_freq = riders_final$freq,
  cyclist_weekend = riders_final$prop_weekend,
  cyclist_time_pc1 = riders_final$time_pc1,
  cyclist_time_pc2 = riders_final$time_pc2,
  cyclist_length_pc1 = riders_final$length_pc1,
  cyclist_length_pc2 = riders_final$length_pc2,
  cyclist_length_balance = riders_final$length_balance,
  cyclist_count_balance = riders_final$count_balance,
  cyclist_median_length = riders_final$median_length,
  cyclist_median_length_diff = riders_final$median_length_diff,
  cyclist_var_length = riders_final$var_length
)

#compile the model (takes a minute or so)
model = rstan::stan_model(file="rider_model1.stan")

#evaluate the model
sampling_iterations = 2e3 #best to use 1e3 or higher
out = rstan::sampling(
  object = model
  , data = data
  , chains = 2
  , iter = sampling_iterations
  , warmup = sampling_iterations/2
  , refresh = sampling_iterations/10 #show an update @ each %10
  , seed = 1
  , init = list(list(beta_length = 0,
                     sigma_a = 1,
                     a_beta_0 = 0,
                     a_beta_freq = 0),
                list(beta_length = 0,
                     sigma_a = 1,
                     a_beta_0 = 0,
                     a_beta_freq = 0))
)

print(out)

plot(out)
```
